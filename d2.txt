import torch
import torch.nn as nn
import numpy as np

# Load input tensor
x = np.load("/remote/us01sgnfs00562/NNSDK/amajala/onnx_model/tensor1_256_768.npy")
input_tensor = torch.from_numpy(x).float()

# Define LayerNorm layer
layer_norm = nn.LayerNorm(x.shape, 9.999999960041972e-13)

# Load scale and bias
s = np.load("/remote/us01sgnfs00562/NNSDK/amajala/hello/nnac/frontend/scale.npy")
b = np.load("/remote/us01sgnfs00562/NNSDK/amajala/hello/nnac/frontend/bias.npy")

# Set weights and bias
with torch.no_grad():
    layer_norm.weight.copy_(torch.tensor(s))
    layer_norm.bias.copy_(torch.tensor(b))

# Wrap the LayerNorm in a module
class LayerNormModel(nn.Module):
    def __init__(self, layer_norm):
        super(LayerNormModel, self).__init__()
        self.layer_norm = layer_norm

    def forward(self, x):
        return self.layer_norm(x)

# Instantiate the model
model = LayerNormModel(layer_norm)

# Export to ONNX
onnx_path = "layernorm_model.onnx"
torch.onnx.export(
    model,                          # The model
    input_tensor,                   # A sample input tensor
    onnx_path,                      # File path to save the ONNX model
    export_params=True,             # Store trained parameter weights inside the model
    opset_version=12,               # ONNX version to export the model
    input_names=['input'],          # Name of the input tensor
    output_names=['output'],        # Name of the output tensor
    dynamic_axes={                  # Dynamic axes for batch size flexibility
        'input': {0: 'batch_size'}, 
        'output': {0: 'batch_size'}
    }
)

print(f"Model has been exported to {onnx_path}")
