struct SubDivFuseBatchNormPattern : public OpRewritePattern<ONNXSubOp> {
  using OpRewritePattern<ONNXSubOp>::OpRewritePattern;

  LogicalResult matchAndRewrite(
      ONNXSubOp subOp, PatternRewriter &rewriter) const final {

    // Match the DivOp corresponding to the SubOp
    ONNXDivOp divOp;
    if (!isSubDivBatchNormMatched(subOp, divOp)) {
      cout << "643";
      return failure();
    }

    Value input = subOp.getOperand(0);
    Type resType = subOp.getResult().getType();

    // Extract constant from the second operand of SubOp
    Value subConstValue = subOp.getOperand(1);
    auto subConstOp = subConstValue.getDefiningOp<ONNXConstantOp>();
    if (!subConstOp) {
      return failure();  // Ensure the operand is a constant.
    }
    
    // Extract the float value from subConstOp
    auto subAttr = subConstOp.value().dyn_cast<mlir::DenseElementsAttr>();
    if (!subAttr || !subAttr.getType().getElementType().isF32()) {
      return failure();
    }
    float subValue = (*subAttr.getValues<float>().begin());

    // Extract constant from the second operand of DivOp
    Value divConstValue = divOp.getOperand(1);
    auto divConstOp = divConstValue.getDefiningOp<ONNXConstantOp>();
    if (!divConstOp) {
      return failure();  // Ensure the operand is a constant.
    }
    
    // Extract the float value from divConstOp
    auto divAttr = divConstOp.value().dyn_cast<mlir::DenseElementsAttr>();
    if (!divAttr || !divAttr.getType().getElementType().isF32()) {
      return failure();
    }
    float divValue = (*divAttr.getValues<float>().begin());

    // Now that we have both subValue and divValue, proceed with BatchNorm fusion logic
    float scale = 1.0f / divValue;
    float bias = -subValue / divValue;
    float mean = 0.0f;
    float variance = 1.0f;
    FloatAttr epsilon = rewriter.getF32FloatAttr(1e-5f);
    FloatAttr momentum = rewriter.getF32FloatAttr(0.9);

    // Create the constants as tensor values.
    Value scaleValue = createFloatTensorConstant(rewriter, subOp.getLoc(), scale);
    Value biasValue = createFloatTensorConstant(rewriter, subOp.getLoc(), bias);
    Value meanValue = createFloatTensorConstant(rewriter, subOp.getLoc(), mean);
    Value varValue = createFloatTensorConstant(rewriter, subOp.getLoc(), variance);
    
    cout << "679679";

    // Define the output types
    SmallVector<Type, 2> outputTypes;
    outputTypes.emplace_back(subOp.getResult().getType());
    outputTypes.emplace_back(divOp.getResult().getType());

    // Create the BatchNormalization operation
    auto bnOp = rewriter.create<ONNXBatchNormalizationOp>(
        subOp.getLoc(), input.getType(), input, scaleValue, biasValue, meanValue, varValue, epsilon, momentum);

    // Replace the Div operation with the result of BatchNorm
    rewriter.replaceOp(divOp, bnOp.getResult());
    
    // Remove the Sub operation
    rewriter.eraseOp(subOp);

    cout << "689689";
    return success();
  }
};
