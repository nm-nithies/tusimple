# Copyright 2023-2024 Synopsys, Inc.
# This Synopsys software and all associated documentation are proprietary
# to Synopsys, Inc. and may only be used pursuant to the terms and conditions
# of a written license agreement with Synopsys, Inc.
# All other use, reproduction, modification, or distribution of the Synopsys
# software or the associated documentation is strictly prohibited.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import networkx as nx
import numpy as np

from nnac.core.log import Logger

logger = Logger("OPTIMIZATION")
"""
Fuse "Sub + Div" to a single "BatchNorm".
"""


def ONNXBatchNormalizationOp : ONNX_Op<"BatchNormalization", [Pure, 
    DeclareOpInterfaceMethods<ShapeInferenceOpInterface>,
    DeclareOpInterfaceMethods<ShapeHelperOpInterface>]> {
  
  let summary = "ONNX BatchNormalization operation";
  let description = [{
    This operator normalizes the input using a set of learnable parameters (scale, bias)
    and a set of statistics (mean, variance), with an added epsilon for numerical stability.
  }];
  
  let arguments = (ins 
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$X,      // Input tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$scale,  // Scale tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$B,      // Bias tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$mean,   // Mean tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$var,    // Variance tensor
    FAttr:$epsilonAttr                                    // Small epsilon value for stability
  );

  let results = (outs 
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$Y       // Output tensor
  );
  
  let extraClassDefinition = [{
    onnx_mlir::ONNXOpShapeHelper * ONNXBatchNormalizationOp::getShapeHelper(mlir::Operation *op, 
        mlir::ArrayRef<mlir::Value> oper, onnx_mlir::IndexExprBuilder *ieb, onnx_mlir::IndexExprScope *scope) {
      onnx_mlir::ONNXOpShapeHelper *sh = new onnx_mlir::ONNXBatchNormalizationOpShapeHelper(op, oper, ieb, scope);
      assert(sh && "failed to allocate shape helper");
      return sh;
    }
  }];
}


def get_constant_operand_index(opt, layer_name):
    # get the index of the constant operand to calculate scale and bias for BN node
    first_operand = opt.G.nodes[layer_name]["input"][0]
    second_operand = opt.G.nodes[layer_name]["input"][1]
    TensorDict = opt.TensorDict
    if first_operand in TensorDict.keys():
        return 0
    elif second_operand in TensorDict.keys():
        return 1
    else:
        return -1


def FuseSubAndDivIntoBN(opt):
    G = opt.G
    TensorDict = opt.TensorDict

    layers = list(nx.topological_sort(G))
    for layer in layers:
        if layer not in G.nodes:
            continue
        succs = list(G.successors(layer))
        if len(succs) > 0:
            sub_layer = list(G.successors(layer))[0]
            if G.nodes[sub_layer].get("op_type", None) == "Sub":
                # only support for 4D input
                if len(opt.ShapeDict[sub_layer]) == 4:
                    div_layer = list(G.successors(sub_layer))[0]
                    if G.nodes[div_layer].get("op_type", None) == "Div":
                        div_succ_layer = list(G.successors(div_layer))[0]
                        div_constant_operand_index = get_constant_operand_index(opt, div_layer)
                        sub_constant_operand_index = get_constant_operand_index(opt, sub_layer)
                        if sub_constant_operand_index == -1 or div_constant_operand_index == -1:
                            # apply pass only for Sub and Div with one constant operand
                            continue
                        div_value = TensorDict.get(G.nodes[div_layer]["input"][div_constant_operand_index], None)
                        sub_value = TensorDict.get(G.nodes[sub_layer]["input"][sub_constant_operand_index], None)

                        bn_name = layer.rsplit('/', 1)[0] + "_BatchNorm"
                        scale = np.array([(1/div_value)], dtype=np.float32)
                        bias = np.array([(-sub_value/div_value)], dtype=np.float32)
                        mean = np.array([0], dtype=np.float32)
                        var = np.array([1], dtype=np.float32)
                        scale_name = bn_name + "/scale"
                        bias_name = bn_name + "/bias"
                        mean_name = bn_name + "/mean"
                        var_name = bn_name + "/var"

                        TensorDict[scale_name] = scale
                        TensorDict[bias_name] = bias
                        TensorDict[mean_name] = mean
                        TensorDict[var_name] = var
                        bn_dict = {
                            "input": [layer, scale_name, bias_name, mean_name, var_name],
                            "output": [bn_name],
                            "op_type":  "BatchNormalization"
                        }

                        G.add_node(bn_name, **bn_dict)
                        G.add_edge(layer, bn_name)
                        G.add_edge(bn_name, div_succ_layer)
                        G.nodes[div_succ_layer]["input"][0] = bn_name
                        # remove Sub and Div layers
                        G.remove_node(sub_layer)
                        G.remove_node(div_layer)

                        opt.passes_counter["FuseSubAndDivIntoBN"] += 1



struct SubDivBatchNormFusePattern : public OpRewritePattern<ONNXSubOp> {
  using OpRewritePattern<ONNXSubOp>::OpRewritePattern;

  LogicalResult matchAndRewrite(
      ONNXSubOp subOp, PatternRewriter &rewriter) const final {
    // Match
    ONNXDivOp divOp;
    if (!isSubDivMatched(subOp, divOp)) // Check if the pattern matches.
      return failure();

    // Fetch input tensors for sub, div, and batch normalization.
    Value subInput1 = subOp.getOperand(0); // First input of Sub
    Value subInput2 = subOp.getOperand(1); // Second input of Sub
    Value divInput = divOp.getOperand(1);  // Div's denominator

    // Assuming the BatchNorm constants (scale, bias, mean, var) are known.
    // These can either be extracted from the surrounding context or passed in.
    Value scale = ...; // Placeholder: Value representing scale
    Value bias = ...;  // Placeholder: Value representing bias
    Value mean = ...;  // Placeholder: Value representing mean
    Value var = ...;   // Placeholder: Value representing variance
    FloatAttr epsilon = rewriter.getF32FloatAttr(1e-5f); // Small epsilon value

    // Rewrite
    Location loc = subOp.getLoc();
    onnx_mlir::MultiDialectBuilder<onnx_mlir::OnnxBuilder> create(rewriter, loc);

    // Create the fused BatchNorm operation with inputs, scale, bias, mean, and variance.
    auto batchNormResult = rewriter.create<ONNXBatchNormalizationOp>(
        loc, subInput1.getType(), subInput1, scale, bias, mean, var, epsilon);

    // Replace the original sub and div operations with the result of batch normalization.
    rewriter.replaceOp(subOp, batchNormResult.getResult(0)); // Replace subOp's result
    rewriter.replaceOp(divOp, batchNormResult.getResult(0)); // Replace divOp's result

    return success();
  }
};

Value createConstantTensor(PatternRewriter &rewriter, float value, Location loc) {
  auto constType = RankedTensorType::get({}, rewriter.getF32Type()); // Scalar
  auto constAttr = DenseElementsAttr::get(constType, value);
  return rewriter.create<ONNXConstantOp>(loc, constType, constAttr);
}






def ONNXBatchNormalizationOp : ONNX_Op<"BatchNormalization", [Pure, 
    DeclareOpInterfaceMethods<ShapeInferenceOpInterface>,
    DeclareOpInterfaceMethods<ShapeHelperOpInterface>]> {
  
  let summary = "ONNX BatchNormalization operation";
  let description = [{
    This operator normalizes the input using a set of learnable parameters (scale, bias)
    and a set of statistics (mean, variance), with an added epsilon for numerical stability.
  }];
  
  let arguments = (ins 
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$X,      // Input tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$scale,  // Scale tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$B,      // Bias tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$mean,   // Mean tensor
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$var,    // Variance tensor
    FAttr:$epsilonAttr                                    // Small epsilon value for stability
  );

  let results = (outs 
    AnyTypeOf<[TensorOf<[BF16]>, TensorOf<[F16]>, TensorOf<[F32]>, TensorOf<[F64]>]>:$Y       // Output tensor
  );
  
  let extraClassDefinition = [{
    onnx_mlir::ONNXOpShapeHelper * ONNXBatchNormalizationOp::getShapeHelper(mlir::Operation *op, 
        mlir::ArrayRef<mlir::Value> oper, onnx_mlir::IndexExprBuilder *ieb, onnx_mlir::IndexExprScope *scope) {
      onnx_mlir::ONNXOpShapeHelper *sh = new onnx_mlir::ONNXBatchNormalizationOpShapeHelper(op, oper, ieb, scope);
      assert(sh && "failed to allocate shape helper");
      return sh;
    }
  }];
}


#include "mlir/IR/PatternMatch.h"
#include "mlir/Pass/Pass.h"
#include "src/Dialect/ONNX/ONNXOps.hpp"
#include "src/Dialect/ONNX/ONNXRewritePass.hpp"
#include "src/Dialect/ONNX/ONNXShapeHelper.hpp"

using namespace mlir;
using namespace onnx_mlir;

namespace {

struct FuseSubAndDivIntoBNPattern : public OpRewritePattern<ONNXSubOp> {
  using OpRewritePattern<ONNXSubOp>::OpRewritePattern;

  LogicalResult matchAndRewrite(ONNXSubOp subOp, PatternRewriter &rewriter) const final {
    // Check if the `Sub` operation is followed by a `Div` operation.
    Operation *subOutput = subOp.getOperation();
    if (!subOutput->hasOneUse()) return failure();

    Operation *divOp = *subOutput->user_begin();
    if (!isa<ONNXDivOp>(divOp)) return failure();

    // Ensure both `Sub` and `Div` have a constant operand.
    Value subInput0 = subOp.getOperand(0);
    Value subInput1 = subOp.getOperand(1);
    Value divInput1 = cast<ONNXDivOp>(divOp).getOperand(1);

    if (!subInput1.getDefiningOp<ONNXConstantOp>() || !divInput1.getDefiningOp<ONNXConstantOp>()) {
      return failure();
    }

    // Retrieve constant values for `Sub` and `Div`.
    auto subConstValue = subInput1.getDefiningOp<ONNXConstantOp>().value().cast<DenseElementsAttr>();
    auto divConstValue = divInput1.getDefiningOp<ONNXConstantOp>().value().cast<DenseElementsAttr>();

    float subValue = subConstValue.getValues<float>()[0];
    float divValue = divConstValue.getValues<float>()[0];

    // Create the `BatchNormalization` attributes.
    auto loc = subOp.getLoc();
    auto scaleAttr = DenseElementsAttr::get(rewriter.getF32TensorAttr(ArrayRef<float>({1.0f / divValue})));
    auto biasAttr = DenseElementsAttr::get(rewriter.getF32TensorAttr(ArrayRef<float>({-subValue / divValue})));
    auto meanAttr = DenseElementsAttr::get(rewriter.getF32TensorAttr(ArrayRef<float>({0.0f})));
    auto varAttr = DenseElementsAttr::get(rewriter.getF32TensorAttr(ArrayRef<float>({1.0f})));
    
    // Create the `BatchNormalization` op.
    Value scale = rewriter.create<ONNXConstantOp>(loc, scaleAttr);
    Value bias = rewriter.create<ONNXConstantOp>(loc, biasAttr);
    Value mean = rewriter.create<ONNXConstantOp>(loc, meanAttr);
    Value variance = rewriter.create<ONNXConstantOp>(loc, varAttr);

    SmallVector<Value, 5> bnInputs = {subOp.getOperand(0), scale, bias, mean, variance};

    // Use the same result type as `Div` for the new `BatchNormalization`.
    Type resultType = divOp->getResult(0).getType();
    Value bnOutput = rewriter.create<ONNXBatchNormalizationInferenceModeOp>(loc, resultType, bnInputs, /*epsilon=*/rewriter.getF64FloatAttr(1e-5), /*momentum=*/rewriter.getF64FloatAttr(0.9));

    // Replace the `Sub` and `Div` with the new `BatchNormalization` operation.
    rewriter.replaceOp(divOp, bnOutput);
    rewriter.eraseOp(subOp);

    return success();
  }
};

struct FuseSubAndDivIntoBNPass : public PassWrapper<FuseSubAndDivIntoBNPass, FunctionPass> {
  void runOnFunction() override {
    auto function = getFunction();

    // Apply the `FuseSubAndDivIntoBNPattern` to the function.
    OwningRewritePatternList patterns(&getContext());
    patterns.insert<FuseSubAndDivIntoBNPattern>(&getContext());
    applyPatternsAndFoldGreedily(function, std::move(patterns));
  }
};

} // end anonymous namespace

// Register the pass.
std::unique_ptr<Pass> createFuseSubAndDivIntoBNPass() {
  return std::make_unique<FuseSubAndDivIntoBNPass>();
}











def ReplaceSum(opt):
    G = opt.G
    layers = list(nx.topological_sort(G))
    for layer in layers:
        if G.nodes[layer].get("op_type", "") == "Sum":
            if len(G.nodes[layer]["input"]) != 2:
                continue
            G.nodes[layer]["op_type"] = "Add"

            opt.passes_counter["ReplaceSum"] += 1









# Copyright 2023-2024 Synopsys, Inc.
# This Synopsys software and all associated documentation are proprietary
# to Synopsys, Inc. and may only be used pursuant to the terms and conditions
# of a written license agreement with Synopsys, Inc.
# All other use, reproduction, modification, or distribution of the Synopsys
# software or the associated documentation is strictly prohibited.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np

from nnac.core.log import Logger

from .single_layer_transforms import remove_one_layer

""" This pass fuses primitive operators into LayerNormalization.
In ONNX dialect it's the MeanVarianceNormalization.
https://github.com/onnx/onnx/blob/main/docs/Operators.md#meanvariancenormalization
(2022/06/17) ONNX v17 adds LayerNormalization
https://github.com/onnx/onnx/blob/main/docs/Operators.md#layernormalization
Checkout their numpy implementation:
https://github.com/onnx/onnx/blob/main/onnx/backend/test/case/node/layernormalization.py
"""


logger = Logger("OPTIMIZATION")

"""      X
       /   |
     /       |
ReduceMean     |
    | |        |  |
    | |_____   |    |
    |       |  |      |
    |         Sub       |
    |          |          |
    |     Mul (i.e. Pow^2) |
    |          |            |
    |      ReduceMean       |
    |          |            |
    |       Add(,epsilon)   |
    |          |            |
    |        Pow(,-0.5)     |
    |          |            |
    |      Mul(,vec(1))     |
    |      broadcasting    /
    |          |         /
     |        / |      /
       |    /     |  /
        Mul        Mul
         |          |
      Sub(0,)       |
     negating      /
         |       /
          |    /
           Add
            |
       LayerNorm_out
"""


def FusePrimitivesIntoLayerNorm(opt):
    """We extract opset_v because we use (un)squeeze nodes around the MVN node,
    And they moved the "axes" parameter from attribute to input when upgraded to v13.
    """
    node_graph = opt.G
    tensor_dict = opt.TensorDict
    shape_dict = opt.ShapeDict
    type_dict = opt.TypeDict
    graph_attrs = opt.graph_attrs

    opset_v = [n.version for n in graph_attrs["opset_import"] if n.domain == ""][0]
    any_fused = find_layernorm_nodes(opt, node_graph, tensor_dict, shape_dict, type_dict, opset_v)

    if any_fused:
        # Now the models always have 3D LayerNorm; it can be
        # checked with shape_dict
        tensor_dict["neg_one"] = np.array([-1]).astype(np.int64)
        pass
        # if the server has onnx updated to v11, we can try function_proto
        # graph_attrs["functions"] = generate_layer_norm_function_proto


def add_layernorm_to_graph(
    optimizer, node_graph, tensor_dict, shape_dict, type_dict,
    ln_ip, ln_op, ln_succs, ln_nodes, ln_eps, ln_axis, opset_v
):
    """Alternate LayerNorm implementations
    1. MeanVarianceNormalization (only supports 4D, so we have to insert Unsqueeze&Squeeze)
    2. Local function (alternative of the above)
    3. ai.onnx v17 LayerNormalization (not tested, not sure other operator works in v17)
    """
    for n in set(ln_nodes):
        node_graph.remove_node(n)

    ln_name = ln_op[0]
    layernorm_node = ln_name + "/layernorm"
    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[ln_name]
    if opset_v >= 13 and "neg_one" not in tensor_dict:
        tensor_dict["neg_one"] = np.array([-1]).astype(np.int64)

    assert ln_eps is not None, "Can not find epsilon value\n"

    # TODO: check if the input model has layernorm-weight and bias.
    # Now I assume None and generate dummy 1s and 0s.

    ip_shape = shape_dict[ln_ip[0]]
    norm_shape = ip_shape[ln_axis:]  # both +ve and -ve axis could work
    tensor_dict[ln_name + "/layernorm_scale"] = np.ones(norm_shape, dtype=np.float32)
    tensor_dict[ln_name + "/layernorm_bias"] = np.zeros(norm_shape, dtype=np.float32)
    shape_dict[layernorm_node] = ip_shape
    type_dict[layernorm_node] = type_dict[ln_ip[0]]
    node_graph.add_node(
        layernorm_node,
        **{
            "op_type": "LayerNormalization",
            "input": [
                ln_ip[0],
                ln_name + "/layernorm_scale",
                ln_name + "/layernorm_bias",
            ],  # [X, SCALE, B], set SCALE and B as 1 and 0 now, and after the fusion of layernorm,
            # we merge the original SCALE and B into the fused layernorm layer
            # "output":[ln_name, ln_name+"/output1", ln_name+"/output2"], # [Y, Mean, InvStdDev],
            # we don't need outputs Mean and InvStdDev
            "output": [
                layernorm_node
            ],  # [Y, Mean, InvStdDev], we don't need outputs Mean and InvStdDev
            "attr_dict": {"axis": ln_axis, "epsilon": ln_eps},
            "domain": "",  # there is only ai.onnx domain now, we expect there is com.microsoft?
        }
    )

    for ip in ln_ip:
        node_graph.add_edge(ip, layernorm_node)
    for op in ln_succs:
        node_graph.add_edge(layernorm_node, op)
    for succ in ln_succs:
        for i in range(len(node_graph.nodes[succ]["input"])):
            if node_graph.nodes[succ]["input"][i] == ln_name:
                node_graph.nodes[succ]["input"][i] = layernorm_node

    optimizer.passes_counter["FusePrimitivesIntoLayerNorm"] += 1

    return layernorm_node


"""
Mean = ReduceMean<axes=normalized_axes>(X)
D = Sub(X, Mean)
DD = Mul(Diff, Diff)
Var = ReduceMean<axes=normalized_axes>(DD)
VarEps = Add(Var, epsilon)
StdDev = Sqrt(VarEps)
InvStdDev = Reciprocal(StdDev)
Normalized = Mul(D, InvStdDev)
"""


def find_layernorm_nodes(optimizer, graph, tensors, shapes, types, opset_v):
    # graph: nx.DiGraph, tensors: tensor_dict, shapes: shape_dict
    any_fused = False
    # pattern inputs, outputs, nodes
    mean_nodes = [n for n, t in graph.nodes(data="op_type") if t == "ReduceMean"]
    for mean_node in mean_nodes:
        if mean_node not in graph.nodes:
            # Var = Mean(SquaredDiff(X-E[x])) can be fused already
            continue
        # pat_in, pat_out, pat_nodes = [], [], []
        # pattern = [pat_in, pat_out, pat_nodes]
        pattern = dict(pattern_inputs=[], pattern_outputs=[], pattern_nodes=[])
        mean_node_out_shape = shapes[mean_node]

        if opset_v < 18:
            pattern["axes"] = graph.nodes[mean_node]["attr_dict"]["axes"].copy()
            for i in range(len(pattern["axes"])):
                if pattern["axes"][i] < 0:
                    pattern["axes"][i] += len(mean_node_out_shape)
            pattern["axes"].sort()
            axes_reduce_on = [i for i in range(pattern["axes"][0], len(mean_node_out_shape))]
            if [mean_node_out_shape[axis] for axis in axes_reduce_on] != [1] * len(axes_reduce_on):
                continue
        else:
            # in opset 18, axes is moved to input field
            pattern["axes"] = None
            if graph.nodes[mean_node]["input"][1] in tensors:
                pattern["axes"] = tensors[graph.nodes[mean_node]["input"][1]].copy()
            if pattern["axes"] is None:
                logger.debug("[DEBUG] Can not find pattern axes in tensor_dict.")
                continue

        for i in range(len(pattern["axes"])):
            if pattern["axes"][i] < 0:
                pattern["axes"][i] += len(mean_node_out_shape)
        pattern["axes"].sort()
        axes_reduce_on = [i for i in range(pattern["axes"][0], len(mean_node_out_shape))]
        if [mean_node_out_shape[axis] for axis in axes_reduce_on] != [1] * len(axes_reduce_on):
            continue

        params = [graph, tensors, mean_node, pattern]
        if not check_Mean(*params):
            continue
        params[2] = pattern["next_node"]  # sub_node =  (X - E[X])
        if not check_D(*params):
            continue
        params[2] = pattern["next_node"]  # DD_node = (X - E[X])^2
        if not check_DD(*params):
            continue
        params[2] = pattern["next_node"]  # Var = Mean( (X - E[X])^2 )
        if not check_Var(*params):
            continue
        params[2] = pattern["next_node"]  # EpsVar = Add(Var, Eps) or Max(Var, 0)
        if not check_VarEps(*params):
            continue
        params[2] = pattern["next_node"]  # StdDev = Sqrt(VarEps)
        if not check_StdDev(*params):
            continue
        params[2] = pattern["next_node"]
        # InvStdDev = Reciprocal(StdDev), Normalized = Mul(D, InvStdDev)
        # 1st pattern is: Div(D, StdDev)
        # 2nd pattern is: StdDev_broad = Mul(StdDev, broadcast);
        #              D*StdDev = Mul(D, StdDev_Broad), X*StdDev = Mul(X, StdDev_Broad);
        # Neg_D*StdDev = Sub(0, D*StdDev),
        # LayerNorm = Add(Neg_D*StdDev, X*StdDev).
        semantics = pattern["semantics"]
        if semantics == "StdDev":
            if not check_StdDev_Normalized(*params):
                assert False, "ENHANCE:already detected StdDev but it's not LayerNorm?"
                continue
        elif semantics == "InvStdDev":
            if not check_InvStdDev_Normalized(*params):
                assert (
                    False
                ), "ENHANCE:already detected InvStdDev but it's not LayerNorm?"
                continue
        else:
            continue
        ln_ip = pattern["pattern_inputs"]
        ln_op = pattern["pattern_outputs"]
        ln_nodes = pattern["pattern_nodes"]
        ln_succs = list(graph.successors(ln_op[0]))
        eps = pattern["epsilon"]
        reduce_axes = pattern["axes"]
        # Just pick the first axis because all dimensions in shape[axis:] are reduced.
        ln_axis = np.min(reduce_axes)
        layernorm_node = add_layernorm_to_graph(
            optimizer, graph, tensors, shapes, types, ln_ip, ln_op, ln_succs, ln_nodes, eps, ln_axis, opset_v
        )
        any_fused = True

        # Check if there are Mul + Add layers can bu fused in LayerNorm
        succs = list(graph.successors(layernorm_node))
        if len(succs) != 1:
            continue
        succ_op_type = graph.nodes[succs[0]].get("op_type", None)
        if succ_op_type == "Mul":
            mul_layer = succs[0]
            succ_succs = list(graph.successors(succs[0]))
            if len(succ_succs) == 1 and graph.nodes[succ_succs[0]].get("op_type", None) == "Add":
                add_layer = succ_succs[0]
                if fuse_mul_into_ln(optimizer, layernorm_node, mul_layer):
                    remove_one_layer(optimizer, mul_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[mul_layer]
                if fuse_add_into_ln(optimizer, layernorm_node, add_layer):
                    remove_one_layer(optimizer, add_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[add_layer]
            else:
                if fuse_mul_into_ln(optimizer, layernorm_node, mul_layer):
                    remove_one_layer(optimizer, mul_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[mul_layer]
        elif succ_op_type == "Add":
            add_layer = succs[0]
            if fuse_add_into_ln(optimizer, layernorm_node, add_layer):
                remove_one_layer(optimizer, add_layer)
                optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[add_layer]

    return any_fused


def get_init(opt, layer):
    G = opt.G
    TensorDict = opt.TensorDict
    for input in G.nodes[layer]["input"]:
        if input in TensorDict:
            return TensorDict[input]
    return None


def fuse_mul_into_ln(opt, ln_layer, mul_layer):
    G = opt.G
    TensorDict = opt.TensorDict
    ln_inputs = G.nodes[ln_layer]["input"]
    scale = TensorDict.get(ln_inputs[1])
    mul_init = get_init(opt, mul_layer)
    if mul_init is None:
        logger.debug(
            "Failed to fuse Mul {} into LayerNorm {}, it's not a constant multiplication.".format(
                mul_layer, ln_layer
            )
        )
        return False
    if mul_init.size != scale.size:
        logger.debug(
            "Failed to fuse Mul {} into LayerNorm {}, the scale size {} v.s. {} doesn't match.".format(
                mul_layer, ln_layer, mul_init.size, scale.size
            )
        )
        return False
    fused_scale = scale * mul_init
    fused_scale_name = ln_inputs[1] + '/fused_mul'
    TensorDict[fused_scale_name] = fused_scale
    del TensorDict[ln_inputs[1]]
    ln_inputs[1] = fused_scale_name
    if len(ln_inputs) > 2:
        B = TensorDict[ln_inputs[2]]
        fused_B = B * mul_init
        fused_B_name = ln_inputs[2] + '/fused_mul'
        TensorDict[fused_B_name] = fused_B
        del TensorDict[ln_inputs[2]]
        ln_inputs[2] = fused_B_name
    logger.debug(
        "Fuse Mul {} into LayerNorm {}.".format(
            mul_layer, ln_layer
        )
    )
    return True


def fuse_add_into_ln(opt, ln_layer, add_layer):
    G = opt.G
    TensorDict = opt.TensorDict
    ln_inputs = G.nodes[ln_layer]["input"]
    add_init = get_init(opt, add_layer)
    if add_init is None:
        logger.debug(
            "Failed to fuse Add {} into LayerNorm {}, it's not a constant addition.".format(
                add_layer, ln_layer
            )
        )
        return False
    if len(ln_inputs) > 2:
        B = TensorDict[ln_inputs[2]]
        fused_B = B + add_init
        fused_B_name = ln_inputs[2] + '/fused_add'
        del TensorDict[ln_inputs[2]]
        ln_inputs[2] = fused_B_name
    else:
        fused_B = B
        fused_B_name = ln_layer + '/fused_add_B'
        ln_inputs.append(fused_B_name)
    TensorDict[fused_B_name] = fused_B
    logger.debug(
        "Fuse Add {} into LayerNorm {}.".format(
            add_layer, ln_layer
        )
    )
    return True


def check_InvStdDev_Normalized(graph, tensors, mul_node, pattern):
    # MulBy1: InvStdDev1 = Mul(InvStdDev, 1) for broadcasting
    succs = list(graph.successors(mul_node))
    if len(succs) != 2:
        return False

    if (
        graph.nodes[succs[0]]["op_type"] != "Mul"
        or graph.nodes[succs[1]]["op_type"] != "Mul"
    ):
        return False

    mul_sub = None
    mul_add = None
    mul0_succ = list(graph.successors(succs[0]))
    if len(mul0_succ) != 1:
        return False
    mul1_succ = list(graph.successors(succs[1]))
    if len(mul1_succ) != 1:
        return False
    mul0_succ_type = graph.nodes[mul0_succ[0]]["op_type"]
    mul1_succ_type = graph.nodes[mul1_succ[0]]["op_type"]

    if mul0_succ_type == "Sub" and mul1_succ_type == "Add":
        mul_sub = succs[0]
        mul_add = succs[1]
    elif mul0_succ_type == "Add" and mul1_succ_type == "Sub":
        mul_sub = succs[1]
        mul_add = succs[0]
    else:
        return False

    sub = list(graph.successors(mul_sub))[0]
    add = list(graph.successors(mul_add))[0]

    if list(graph.successors(sub))[0] != add:
        return False

    pattern["pattern_nodes"].append(mul_node)
    pattern["pattern_nodes"].extend(succs)
    pattern["pattern_nodes"].append(sub)
    pattern["pattern_nodes"].append(add)
    pattern["pattern_outputs"].append(add)
    return True


def check_StdDev_Normalized(graph, tensors, div_node, pattern):
    # Normalized = Div(D, StdDev)
    preds = list(graph.predecessors(div_node))
    if preds[0] != pattern["pattern_nodes"][0]:
        # when we check Mean = ReduceMean(X), we also appended the second D = Sub(X, Mean)
        return False
    # A general check
    for pred in preds:
        if pred not in pattern["pattern_nodes"]:
            return False
    op_type = graph.nodes[div_node]["op_type"]
    if op_type != "Div":
        return False

    pattern["pattern_nodes"].append(div_node)
    pattern["pattern_outputs"].append(div_node)
    return True


def check_StdDev(graph, tensors, stddev_node, pattern):
    succs = list(graph.successors(stddev_node))
    if len(succs) != 1:
        return False
    # it should be a sqrt
    op_type = graph.nodes[stddev_node]["op_type"]
    pattern["semantics"] = "StdDev"
    if op_type == "Pow":
        inputs = graph.nodes[stddev_node]["input"]
        exp = tensors[inputs[1]]
        if exp != -0.5:  # It's actually InvStdDev
            return False
        pattern["semantics"] = "InvStdDev"
    elif op_type != "Sqrt":  # StdDev
        return False
    pattern["pattern_nodes"].append(stddev_node)
    pattern["next_node"] = succs[0]
    return True


def check_VarEps(graph, tensors, vareps_node, pattern):
    succs = list(graph.successors(vareps_node))
    if len(succs) != 1:
        return False
    op_type = graph.nodes[vareps_node]["op_type"]
    # VarEps is [Add(Var,Eps~=1e-12)] or [Max(Var,0)]
    if op_type not in ["Add", "Max"]:
        return False
    eps = None
    if op_type == "Max":
        eps = 1e-12
    elif op_type == "Add":
        for input in graph.nodes[vareps_node]["input"]:
            if input in tensors:
                # In detr_resnet50 the Eps of Add(Var, Eps) has shape of (768,1,1)
                # here we utilize np.mean() to easily get the eps value.
                eps = np.mean(tensors[input])
                break
    pattern["pattern_nodes"].append(vareps_node)
    pattern["next_node"] = succs[0]
    pattern["epsilon"] = float(eps)
    return True


def check_Var(graph, tensors, var_node, pattern):
    if graph.nodes[var_node]["op_type"] != "ReduceMean":
        return False
    succs = list(graph.successors(var_node))
    if len(succs) != 1:
        return False
    pattern["pattern_nodes"].append(var_node)
    pattern["next_node"] = succs[0]
    return True


def check_DD(graph, tensors, square_node, pattern):
    succs = list(graph.successors(square_node))
    if len(succs) != 1:
        return False
    op_type = graph.nodes[square_node]["op_type"]
    if op_type not in ["Pow", "Mul"]:
        return False

    inputs = graph.nodes[square_node]["input"]
    if op_type == "Pow":
        exp = tensors[inputs[1]]
        if exp != 2:
            return False
    elif op_type == "Mul":
        if inputs[0] != inputs[1]:
            return False
    else:
        return False
    pattern["pattern_nodes"].append(square_node)
    pattern["next_node"] = succs[0]
    return True


def check_D(graph, tensors, sub_node, pattern):
    if graph.nodes[sub_node]["op_type"] != "Sub":
        return False
    succs = list(graph.successors(sub_node))
    # Either succs=[Mul], [Pow], or [Pow, Div]. In the 3rd pattern, Div is used for (X-EX)/Var.
    # In the first two patterns they use other nodes for that division.
    # We select the Square node as next_node. (Mul/Pow)
    if len(succs) < 1 or len(succs) > 2:
        return False
    pattern["pattern_nodes"].append(sub_node)
    pattern["next_node"] = succs[0]
    return True


def check_Mean(graph, tensors, mean_node, pattern):
    """We will have two dependency to Mean:
    D = Sub(X, Mean)
    Normalized = Mul(D, InvStdDev)
    So the #sucessors should be two, and one of them must be Sub for D
    another is Div (or the same Sub? -> this can be optimized by fuse_identical_sibling_layers.py)
    """
    # We'll have two suceesors, so check len
    succs = list(graph.successors(mean_node))
    # Either succs=[Sub,Mul], [Sub, Sub] or [Sub]
    if len(succs) < 1 or len(succs) > 2:
        return False
    if graph.nodes[succs[0]]["op_type"] != "Sub":
        return False
    if len(succs) == 2:
        succ1_type = graph.nodes[succs[1]]["op_type"]
        if succ1_type == "Sub":
            # the second input can be Div, or [Sub -> Div],
            # just fuse the dummpy Sub here
            pattern["pattern_nodes"].append(succs[1])
        elif succ1_type != "Mul":  # another pattern is Mul
            return False
    else:  # len(succs) == 1, (model: mmlab/vit)
        # we will use this node to indicate the operand of the Division (X-EX)/StdDev
        pattern["pattern_nodes"].append(succs[0])
    pattern["pattern_nodes"].append(mean_node)
    pattern["pattern_inputs"].extend(list(graph.predecessors(mean_node)))
    pattern["next_node"] = succs[0]
    return True
