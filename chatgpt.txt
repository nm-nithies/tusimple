This function merges all parallel convolution layer weights and biases into a single set. Additionally, it consolidates the scale and zero-point values for both weights and biases, ensuring compatibility across all channels. This is necessary because the QDQ (Quantize-Dequantize) nodes have different scale and zero-point values for each channel in the convolution layer.
