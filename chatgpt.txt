Nithies:
Fixed the issues faced in Yolov8 qdq subgraph .
Now added Dequantized node before tranpose 
But this creates issues in RemoveTransposeBeforeSoftmax pass 
Currenty working on fixing this issue 

Nithies NM:
Tried to find the root cause for mlp_mixer model 
Checked the different subgraph outputs in the mlp_mixer. Book 1.xlsx
Currently checking the compare.py file 

Nithies:
Ran Onnx Slim for SwinIR Model
Tried to fix the max_diff for mlp_mixer Model. Tried to legalize the model with realistic image values. But there is no deviation in max-diff
Compared the LayerNorm Pattern with other existing model Layernorm Patterns
Yvonne Chen Can you please suggest me any idea to find the root cause for the max-diff

Tasks: 17-02-2025
Kathirvel B:
 
Worked on setting up the MobileNetV2 Pytorch repo to do the QAT and produce the QDQ model.
Setup https://github.com/yakhyo/mobilenetv2-pytorch repo, but when running the QAT API, the QAT process is getting stuck.
 
Tried using 
torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)
But it is giving zero accuracy with the existing ILSVRC2012 dataset. 
 
Harika:
Yolov8:
Tried to add FM model accuracy support
When passed original yolov8 tflite quantized model, facing issue while generating FM 
/remote/us01sgnfs00562/NNSDK/harikam/har/nnac/nnac_backend/src/conversion/converter.cc:235 -> Unhandled op: Cast 
 
When passed already optimized model which is sliced by sne4onnx, facing issue
Pass failed: Annotate L0 fusions
Backend initialization failed: Graph Backend transformations failed
Failed to compile the graph: Graph Backend transformations failed
 
Able to generate functional model with the last nodes specified in the new_yolov7_models repo branch
Trying to add postprocessing support.
Currently setting up https://github.com/d-li14/mobilenetv2.pytorch repo. and this requires the dataset in the particular format where classes are seperate folders and images are present inside it. The dataset preparation is in progress
 
NITHIES:
For fix transpose and softmax issues for qdq cut model task, required futher enhancement in the previous fix 
Made changes in convert_Softmax_to_NCHW pass to fix the issue 
Triggered the regression
 
mlp_mixer legalization failure
Tried to find the root cause for the max_diff
 
NITHIES:
Tried to fix the hanging Qunatized and dequantized Nodes
Gone through the MoveTransposeToEnd Pass, Tried to fix this issue. But stilll faces the hanging node issue
Nithies
Fixed yolo_nas hanging qdq_nodes issue
Fixed fix transpose and softmax issues for qdq cut model issue
Uploaded SwinIr model in onnx repo
