import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class Pattern1Model(nn.Module):
    def __init__(self):
        super(Pattern1Model, self).__init__()
        self.conv1 = nn.Conv2d(128, 128, kernel_size=1, bias=False)
        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=True)
        self.relu1 = nn.ReLU()
        self.concat_dim = 1  # channel dimension

        # BatchNorm expects 256 channels after concat
        self.bn = nn.BatchNorm2d(256)
        self.relu2 = nn.ReLU()

        # Initialize BatchNorm manually as per requirements
        self.bn.weight.data.fill_(1.0)  # scale = 1
        self.bn.bias.data.fill_(0.0)    # bias = 0
        self.bn.running_mean.data = torch.abs(torch.randn(256)) + 0.1  # positive mean
        self.bn.running_var.data = torch.abs(torch.randn(256)) + 0.1   # positive var

    def forward(self, x):
        out1 = self.relu1(self.conv1(x))
        out2 = self.conv2(x)
        concat_out = torch.cat((out1, out2), dim=self.concat_dim)
        out = self.bn(concat_out)
        out = self.relu2(out)
        return out

# Instantiate and prepare model
model = Pattern1Model()
model.eval()

# Dummy input: batch_size=1, channels=128, height=32, width=32
dummy_input = torch.randn(1, 128, 32, 32)

# Export to ONNX
torch.onnx.export(
    model,
    dummy_input,
    "pattern1_model.onnx",
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
    opset_version=11
)

print("ONNX export completed: pattern1_model.onnx")
