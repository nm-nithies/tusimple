
import networkx as nx

from nnac.core.log import Logger

from .single_layer_transforms import remove_one_layer

logger = Logger("OPTIMIZATION")

""" Remove consecutive Resize nodes
"""


def RemoveConsecutiveResizes(opt):
    G = opt.G

    layers = list(nx.topological_sort(G))
    for layer in layers:
        if layer in G.nodes:
            op_type = G.nodes[layer].get("op_type", None)
            if op_type != "Resize":
                continue

            remove_resizes = [layer]
            succ_layer = list(G.successors(layer))
            while (
                len(succ_layer) == 1
                and G.nodes[succ_layer[0]].get("op_type", None) == "Resize"
            ):
                remove_resizes.append(succ_layer[0])
                succ_layer = list(G.successors(succ_layer[0]))

            if len(remove_resizes) == 1:
                continue

            for n in remove_resizes[:-1]:
                remove_one_layer(opt, n)
                logger.debug("[DEBUG] Remove consecutive Resize layer {}.".format(n))

                opt.passes_counter["RemoveConsecutiveResizes"] += 1




static bool isConsecutiveResizeOpMatched(
    ONNXResizeOp resizeOp1, ONNXResizeOp &resizeOp2) {
  resizeOp2 = nullptr;
  for (Operation *user : resizeOp1->getUsers()) {
    if (isa<ONNXResizeOp>(user) && !resizeOp2) {
      std::cout << "If condition";
      resizeOp2 = cast<ONNXResizeOp>(user);
    } else {
      return false;
    }
  }
  return resizeOp2 != nullptr;
}



struct ReplaceFirstResizeWithSecondPattern : public OpRewritePattern<ONNXResizeOp> {
  using OpRewritePattern<ONNXResizeOp>::OpRewritePattern;

  LogicalResult matchAndRewrite(
      ONNXResizeOp resizeOp1, PatternRewriter &rewriter) const final {
    // Check if resizeOp1 is followed by another consecutive Resize operation
    ONNXResizeOp resizeOp2;
    if (!isConsecutiveResizeOpMatched(resizeOp1, resizeOp2))
      return failure(); // No consecutive resize found

    // Replace all uses of the first ResizeOp with the second ResizeOp's result
    rewriter.replaceOp(resizeOp1, resizeOp2.getResult());

    // Optionally, you can erase the first ResizeOp if it's no longer used elsewhere
    rewriter.eraseOp(resizeOp1);

    return success();
  }
};




import torch
import torch.nn as nn
import torch.onnx

# Define a custom Resize layer (PyTorch doesn't have a built-in Resize layer)
class ResizeLayer(nn.Module):
    def __init__(self, size):
        super(ResizeLayer, self).__init__()
        self.size = size

    def forward(self, x):
        return torch.nn.functional.interpolate(x, size=self.size, mode='bilinear')

# Define the model
class CustomModel(nn.Module):
    def __init__(self):
        super(CustomModel, self).__init__()
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.resize1 = ResizeLayer(size=(16, 16))  # Resize to 16x16
        self.resize2 = ResizeLayer(size=(8, 8))    # Resize to 8x8
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(8 * 8 * 3, 128)       # Linear layer 1
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 10)              # Linear layer 2
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.maxpool(x)
        x = self.resize1(x)
        x = self.resize2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.softmax(x)
        return x

# Initialize the model
model = CustomModel()

# Dummy input for the model (e.g., 1 image with 3 channels of size 32x32)
dummy_input = torch.randn(1, 3, 32, 32)

# Export the model to ONNX
torch.onnx.export(
    model,                      # model to be exported
    dummy_input,                # input to the model
    "custom_model.onnx",        # where to save the ONNX model
    input_names=["input"],      # the model's input names
    output_names=["output"],    # the model's output names
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},  # support dynamic batching
    opset_version=11            # ONNX opset version to use
)

print("Model has been exported to custom_model.onnx")
