The RecomposeLayerNormFromMulPattern pass identifies ONNX Layer Normalization patterns by analyzing operations like Mul, Div, Sqrt, and ReduceMean.
It replaces the matched patterns with optimized ONNX LayerNorm or RMSLayerNorm operations, enhancing performance and reducing complexity in the computation graph.



The RecomposeGeluFromMulPattern pass rewrites Gelu activation functions represented as multiplications in ONNX by identifying exact or approximate forms. 
It replaces matched structures with a concise Gelu operation, maintaining the intended behavior of the computational graph.



This pass identifies a pattern of DequantizeLinear + MatMul + QuantizeLinear operations and rewrites it into a more efficient QLinearMatMul operation. 
It optimizes matrix multiplication in quantized neural networks by recomposing these operations into a single fused QLinearMatMul.

*****************************************************************************************************************************************************************************************

This pass rewrites the ONNXSoftmax operation by decomposing it into  ReduceMax, Subtract, Exp, ReduceSum, and Divide Operation. 
It optimizes the softmax computation by explicitly creating these intermediate steps, potentially enhancing performance or enabling further transformations.

This pass fuses Concat, Shape, and Transpose into a custom ONNXConcatShapeTransposeOp

This pass decomposes FusedMatMul into MatMul and Transpose operations with scaling by alpha

This pass converts ONNXInstanceNormalizationOp into LayerNorm, reshaping scale and bias for improved performance.

The SumToAddPattern rewrites ONNXSumOp into multiple ONNXAddOp operations, replacing input summation with individual additions.

The ReplaceCastLikeByCastPattern transforms ONNXCastLikeOp into an appropriate cast operation based on the target type, preserving the output type. It handles both ranked and unranked tensor types, ensuring the output is correctly cast to match the specified target type.

This pass replaces a 1x1 convolution with a matrix multiplication, reshaping inputs and outputs for efficiency. Bias is handled if present.

The provided C++ code parses the Einsum equation and computes the axes for summation and contraction to facilitate the decomposition of the Einsum operation into MatMul and ReduceSum operations.
