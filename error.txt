# Copyright 2023-2024 Synopsys, Inc.
# This Synopsys software and all associated documentation are proprietary
# to Synopsys, Inc. and may only be used pursuant to the terms and conditions
# of a written license agreement with Synopsys, Inc.
# All other use, reproduction, modification, or distribution of the Synopsys
# software or the associated documentation is strictly prohibited.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np

from nnac.core.log import Logger

from .single_layer_transforms import remove_one_layer

""" This pass fuses primitive operators into LayerNormalization.
In ONNX dialect it's the MeanVarianceNormalization.
https://github.com/onnx/onnx/blob/main/docs/Operators.md#meanvariancenormalization
(2022/06/17) ONNX v17 adds LayerNormalization
https://github.com/onnx/onnx/blob/main/docs/Operators.md#layernormalization
Checkout their numpy implementation:
https://github.com/onnx/onnx/blob/main/onnx/backend/test/case/node/layernormalization.py
"""


logger = Logger("OPTIMIZATION")

"""      X
       /   |
     /       |
ReduceMean     |
    | |        |  |
    | |_____   |    |
    |       |  |      |
    |         Sub       |
    |          |          |
    |     Mul (i.e. Pow^2) |
    |          |            |
    |      ReduceMean       |
    |          |            |
    |       Add(,epsilon)   |
    |          |            |
    |        Pow(,-0.5)     |
    |          |            |
    |      Mul(,vec(1))     |
    |      broadcasting    /
    |          |         /
     |        / |      /
       |    /     |  /
        Mul        Mul
         |          |
      Sub(0,)       |
     negating      /
         |       /
          |    /
           Add
            |
       LayerNorm_out
"""


def FusePrimitivesIntoLayerNorm(opt):
    """We extract opset_v because we use (un)squeeze nodes around the MVN node,
    And they moved the "axes" parameter from attribute to input when upgraded to v13.
    """
    node_graph = opt.G
    tensor_dict = opt.TensorDict
    shape_dict = opt.ShapeDict
    type_dict = opt.TypeDict
    graph_attrs = opt.graph_attrs

    opset_v = [n.version for n in graph_attrs["opset_import"] if n.domain == ""][0]
    any_fused = find_layernorm_nodes(opt, node_graph, tensor_dict, shape_dict, type_dict, opset_v)

    if any_fused:
        # Now the models always have 3D LayerNorm; it can be
        # checked with shape_dict
        tensor_dict["neg_one"] = np.array([-1]).astype(np.int64)
        pass
        # if the server has onnx updated to v11, we can try function_proto
        # graph_attrs["functions"] = generate_layer_norm_function_proto


def add_layernorm_to_graph(
    optimizer, node_graph, tensor_dict, shape_dict, type_dict,
    ln_ip, ln_op, ln_succs, ln_nodes, ln_eps, ln_axis, opset_v
):
    """Alternate LayerNorm implementations
    1. MeanVarianceNormalization (only supports 4D, so we have to insert Unsqueeze&Squeeze)
    2. Local function (alternative of the above)
    3. ai.onnx v17 LayerNormalization (not tested, not sure other operator works in v17)
    """
    for n in set(ln_nodes):
        node_graph.remove_node(n)

    ln_name = ln_op[0]
    layernorm_node = ln_name + "/layernorm"
    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[ln_name]
    if opset_v >= 13 and "neg_one" not in tensor_dict:
        tensor_dict["neg_one"] = np.array([-1]).astype(np.int64)

    assert ln_eps is not None, "Can not find epsilon value\n"

    # TODO: check if the input model has layernorm-weight and bias.
    # Now I assume None and generate dummy 1s and 0s.

    ip_shape = shape_dict[ln_ip[0]]
    norm_shape = ip_shape[ln_axis:]  # both +ve and -ve axis could work
    tensor_dict[ln_name + "/layernorm_scale"] = np.ones(norm_shape, dtype=np.float32)
    tensor_dict[ln_name + "/layernorm_bias"] = np.zeros(norm_shape, dtype=np.float32)
    shape_dict[layernorm_node] = ip_shape
    type_dict[layernorm_node] = type_dict[ln_ip[0]]
    node_graph.add_node(
        layernorm_node,
        **{
            "op_type": "LayerNormalization",
            "input": [
                ln_ip[0],
                ln_name + "/layernorm_scale",
                ln_name + "/layernorm_bias",
            ],  # [X, SCALE, B], set SCALE and B as 1 and 0 now, and after the fusion of layernorm,
            # we merge the original SCALE and B into the fused layernorm layer
            # "output":[ln_name, ln_name+"/output1", ln_name+"/output2"], # [Y, Mean, InvStdDev],
            # we don't need outputs Mean and InvStdDev
            "output": [
                layernorm_node
            ],  # [Y, Mean, InvStdDev], we don't need outputs Mean and InvStdDev
            "attr_dict": {"axis": ln_axis, "epsilon": ln_eps},
            "domain": "",  # there is only ai.onnx domain now, we expect there is com.microsoft?
        }
    )

    for ip in ln_ip:
        node_graph.add_edge(ip, layernorm_node)
    for op in ln_succs:
        node_graph.add_edge(layernorm_node, op)
    for succ in ln_succs:
        for i in range(len(node_graph.nodes[succ]["input"])):
            if node_graph.nodes[succ]["input"][i] == ln_name:
                node_graph.nodes[succ]["input"][i] = layernorm_node

    optimizer.passes_counter["FusePrimitivesIntoLayerNorm"] += 1

    return layernorm_node


"""
Mean = ReduceMean<axes=normalized_axes>(X)
D = Sub(X, Mean)
DD = Mul(Diff, Diff)
Var = ReduceMean<axes=normalized_axes>(DD)
VarEps = Add(Var, epsilon)
StdDev = Sqrt(VarEps)
InvStdDev = Reciprocal(StdDev)
Normalized = Mul(D, InvStdDev)
"""


def find_layernorm_nodes(optimizer, graph, tensors, shapes, types, opset_v):
    # graph: nx.DiGraph, tensors: tensor_dict, shapes: shape_dict
    any_fused = False
    # pattern inputs, outputs, nodes
    mean_nodes = [n for n, t in graph.nodes(data="op_type") if t == "ReduceMean"]
    for mean_node in mean_nodes:
        if mean_node not in graph.nodes:
            # Var = Mean(SquaredDiff(X-E[x])) can be fused already
            continue
        # pat_in, pat_out, pat_nodes = [], [], []
        # pattern = [pat_in, pat_out, pat_nodes]
        pattern = dict(pattern_inputs=[], pattern_outputs=[], pattern_nodes=[])
        mean_node_out_shape = shapes[mean_node]

        if opset_v < 18:
            pattern["axes"] = graph.nodes[mean_node]["attr_dict"]["axes"].copy()
            for i in range(len(pattern["axes"])):
                if pattern["axes"][i] < 0:
                    pattern["axes"][i] += len(mean_node_out_shape)
            pattern["axes"].sort()
            axes_reduce_on = [i for i in range(pattern["axes"][0], len(mean_node_out_shape))]
            if [mean_node_out_shape[axis] for axis in axes_reduce_on] != [1] * len(axes_reduce_on):
                continue
        else:
            # in opset 18, axes is moved to input field
            pattern["axes"] = None
            if graph.nodes[mean_node]["input"][1] in tensors:
                pattern["axes"] = tensors[graph.nodes[mean_node]["input"][1]].copy()
            if pattern["axes"] is None:
                logger.debug("[DEBUG] Can not find pattern axes in tensor_dict.")
                continue

        for i in range(len(pattern["axes"])):
            if pattern["axes"][i] < 0:
                pattern["axes"][i] += len(mean_node_out_shape)
        pattern["axes"].sort()
        axes_reduce_on = [i for i in range(pattern["axes"][0], len(mean_node_out_shape))]
        if [mean_node_out_shape[axis] for axis in axes_reduce_on] != [1] * len(axes_reduce_on):
            continue

        params = [graph, tensors, mean_node, pattern]
        if not check_Mean(*params):
            continue
        params[2] = pattern["next_node"]  # sub_node =  (X - E[X])
        if not check_D(*params):
            continue
        params[2] = pattern["next_node"]  # DD_node = (X - E[X])^2
        if not check_DD(*params):
            continue
        params[2] = pattern["next_node"]  # Var = Mean( (X - E[X])^2 )
        if not check_Var(*params):
            continue
        params[2] = pattern["next_node"]  # EpsVar = Add(Var, Eps) or Max(Var, 0)
        if not check_VarEps(*params):
            continue
        params[2] = pattern["next_node"]  # StdDev = Sqrt(VarEps)
        if not check_StdDev(*params):
            continue
        params[2] = pattern["next_node"]
        # InvStdDev = Reciprocal(StdDev), Normalized = Mul(D, InvStdDev)
        # 1st pattern is: Div(D, StdDev)
        # 2nd pattern is: StdDev_broad = Mul(StdDev, broadcast);
        #              D*StdDev = Mul(D, StdDev_Broad), X*StdDev = Mul(X, StdDev_Broad);
        # Neg_D*StdDev = Sub(0, D*StdDev),
        # LayerNorm = Add(Neg_D*StdDev, X*StdDev).
        semantics = pattern["semantics"]
        if semantics == "StdDev":
            if not check_StdDev_Normalized(*params):
                assert False, "ENHANCE:already detected StdDev but it's not LayerNorm?"
                continue
        elif semantics == "InvStdDev":
            if not check_InvStdDev_Normalized(*params):
                assert (
                    False
                ), "ENHANCE:already detected InvStdDev but it's not LayerNorm?"
                continue
        else:
            continue
        ln_ip = pattern["pattern_inputs"]
        ln_op = pattern["pattern_outputs"]
        ln_nodes = pattern["pattern_nodes"]
        ln_succs = list(graph.successors(ln_op[0]))
        eps = pattern["epsilon"]
        reduce_axes = pattern["axes"]
        # Just pick the first axis because all dimensions in shape[axis:] are reduced.
        ln_axis = np.min(reduce_axes)
        layernorm_node = add_layernorm_to_graph(
            optimizer, graph, tensors, shapes, types, ln_ip, ln_op, ln_succs, ln_nodes, eps, ln_axis, opset_v
        )
        any_fused = True

        # Check if there are Mul + Add layers can bu fused in LayerNorm
        succs = list(graph.successors(layernorm_node))
        if len(succs) != 1:
            continue
        succ_op_type = graph.nodes[succs[0]].get("op_type", None)
        if succ_op_type == "Mul":
            mul_layer = succs[0]
            succ_succs = list(graph.successors(succs[0]))
            if len(succ_succs) == 1 and graph.nodes[succ_succs[0]].get("op_type", None) == "Add":
                add_layer = succ_succs[0]
                if fuse_mul_into_ln(optimizer, layernorm_node, mul_layer):
                    remove_one_layer(optimizer, mul_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[mul_layer]
                if fuse_add_into_ln(optimizer, layernorm_node, add_layer):
                    remove_one_layer(optimizer, add_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[add_layer]
            else:
                if fuse_mul_into_ln(optimizer, layernorm_node, mul_layer):
                    remove_one_layer(optimizer, mul_layer)
                    optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[mul_layer]
        elif succ_op_type == "Add":
            add_layer = succs[0]
            if fuse_add_into_ln(optimizer, layernorm_node, add_layer):
                remove_one_layer(optimizer, add_layer)
                optimizer.compare_dict[layernorm_node] = optimizer.compare_dict[add_layer]

    return any_fused


def get_init(opt, layer):
    G = opt.G
    TensorDict = opt.TensorDict
    for input in G.nodes[layer]["input"]:
        if input in TensorDict:
            return TensorDict[input]
    return None


def fuse_mul_into_ln(opt, ln_layer, mul_layer):
    G = opt.G
    TensorDict = opt.TensorDict
    ln_inputs = G.nodes[ln_layer]["input"]
    scale = TensorDict.get(ln_inputs[1])
    mul_init = get_init(opt, mul_layer)
    if mul_init is None:
        logger.debug(
            "Failed to fuse Mul {} into LayerNorm {}, it's not a constant multiplication.".format(
                mul_layer, ln_layer
            )
        )
        return False
    if mul_init.size != scale.size:
        logger.debug(
            "Failed to fuse Mul {} into LayerNorm {}, the scale size {} v.s. {} doesn't match.".format(
                mul_layer, ln_layer, mul_init.size, scale.size
            )
        )
        return False
    fused_scale = scale * mul_init
    fused_scale_name = ln_inputs[1] + '/fused_mul'
    TensorDict[fused_scale_name] = fused_scale
    del TensorDict[ln_inputs[1]]
    ln_inputs[1] = fused_scale_name
    if len(ln_inputs) > 2:
        B = TensorDict[ln_inputs[2]]
        fused_B = B * mul_init
        fused_B_name = ln_inputs[2] + '/fused_mul'
        TensorDict[fused_B_name] = fused_B
        del TensorDict[ln_inputs[2]]
        ln_inputs[2] = fused_B_name
    logger.debug(
        "Fuse Mul {} into LayerNorm {}.".format(
            mul_layer, ln_layer
        )
    )
    return True


def fuse_add_into_ln(opt, ln_layer, add_layer):
    G = opt.G
    TensorDict = opt.TensorDict
    ln_inputs = G.nodes[ln_layer]["input"]
    add_init = get_init(opt, add_layer)
    if add_init is None:
        logger.debug(
            "Failed to fuse Add {} into LayerNorm {}, it's not a constant addition.".format(
                add_layer, ln_layer
            )
        )
        return False
    if len(ln_inputs) > 2:
        B = TensorDict[ln_inputs[2]]
        fused_B = B + add_init
        fused_B_name = ln_inputs[2] + '/fused_add'
        del TensorDict[ln_inputs[2]]
        ln_inputs[2] = fused_B_name
    else:
        fused_B = B
        fused_B_name = ln_layer + '/fused_add_B'
        ln_inputs.append(fused_B_name)
    TensorDict[fused_B_name] = fused_B
    logger.debug(
        "Fuse Add {} into LayerNorm {}.".format(
            add_layer, ln_layer
        )
    )
    return True


def check_InvStdDev_Normalized(graph, tensors, mul_node, pattern):
    # MulBy1: InvStdDev1 = Mul(InvStdDev, 1) for broadcasting
    succs = list(graph.successors(mul_node))
    if len(succs) != 2:
        return False

    if (
        graph.nodes[succs[0]]["op_type"] != "Mul"
        or graph.nodes[succs[1]]["op_type"] != "Mul"
    ):
        return False

    mul_sub = None
    mul_add = None
    mul0_succ = list(graph.successors(succs[0]))
    if len(mul0_succ) != 1:
        return False
    mul1_succ = list(graph.successors(succs[1]))
    if len(mul1_succ) != 1:
        return False
    mul0_succ_type = graph.nodes[mul0_succ[0]]["op_type"]
    mul1_succ_type = graph.nodes[mul1_succ[0]]["op_type"]

    if mul0_succ_type == "Sub" and mul1_succ_type == "Add":
        mul_sub = succs[0]
        mul_add = succs[1]
    elif mul0_succ_type == "Add" and mul1_succ_type == "Sub":
        mul_sub = succs[1]
        mul_add = succs[0]
    else:
        return False

    sub = list(graph.successors(mul_sub))[0]
    add = list(graph.successors(mul_add))[0]

    if list(graph.successors(sub))[0] != add:
        return False

    pattern["pattern_nodes"].append(mul_node)
    pattern["pattern_nodes"].extend(succs)
    pattern["pattern_nodes"].append(sub)
    pattern["pattern_nodes"].append(add)
    pattern["pattern_outputs"].append(add)
    return True


def check_StdDev_Normalized(graph, tensors, div_node, pattern):
    # Normalized = Div(D, StdDev)
    preds = list(graph.predecessors(div_node))
    if preds[0] != pattern["pattern_nodes"][0]:
        # when we check Mean = ReduceMean(X), we also appended the second D = Sub(X, Mean)
        return False
    # A general check
    for pred in preds:
        if pred not in pattern["pattern_nodes"]:
            return False
    op_type = graph.nodes[div_node]["op_type"]
    if op_type != "Div":
        return False

    pattern["pattern_nodes"].append(div_node)
    pattern["pattern_outputs"].append(div_node)
    return True


def check_StdDev(graph, tensors, stddev_node, pattern):
    succs = list(graph.successors(stddev_node))
    if len(succs) != 1:
        return False
    # it should be a sqrt
    op_type = graph.nodes[stddev_node]["op_type"]
    pattern["semantics"] = "StdDev"
    if op_type == "Pow":
        inputs = graph.nodes[stddev_node]["input"]
        exp = tensors[inputs[1]]
        if exp != -0.5:  # It's actually InvStdDev
            return False
        pattern["semantics"] = "InvStdDev"
    elif op_type != "Sqrt":  # StdDev
        return False
    pattern["pattern_nodes"].append(stddev_node)
    pattern["next_node"] = succs[0]
    return True


def check_VarEps(graph, tensors, vareps_node, pattern):
    succs = list(graph.successors(vareps_node))
    if len(succs) != 1:
        return False
    op_type = graph.nodes[vareps_node]["op_type"]
    # VarEps is [Add(Var,Eps~=1e-12)] or [Max(Var,0)]
    if op_type not in ["Add", "Max"]:
        return False
    eps = None
    if op_type == "Max":
        eps = 1e-12
    elif op_type == "Add":
        for input in graph.nodes[vareps_node]["input"]:
            if input in tensors:
                # In detr_resnet50 the Eps of Add(Var, Eps) has shape of (768,1,1)
                # here we utilize np.mean() to easily get the eps value.
                eps = np.mean(tensors[input])
                break
    pattern["pattern_nodes"].append(vareps_node)
    pattern["next_node"] = succs[0]
    pattern["epsilon"] = float(eps)
    return True


def check_Var(graph, tensors, var_node, pattern):
    if graph.nodes[var_node]["op_type"] != "ReduceMean":
        return False
    succs = list(graph.successors(var_node))
    if len(succs) != 1:
        return False
    pattern["pattern_nodes"].append(var_node)
    pattern["next_node"] = succs[0]
    return True


def check_DD(graph, tensors, square_node, pattern):
    succs = list(graph.successors(square_node))
    if len(succs) != 1:
        return False
    op_type = graph.nodes[square_node]["op_type"]
    if op_type not in ["Pow", "Mul"]:
        return False

    inputs = graph.nodes[square_node]["input"]
    if op_type == "Pow":
        exp = tensors[inputs[1]]
        if exp != 2:
            return False
    elif op_type == "Mul":
        if inputs[0] != inputs[1]:
            return False
    else:
        return False
    pattern["pattern_nodes"].append(square_node)
    pattern["next_node"] = succs[0]
    return True


def check_D(graph, tensors, sub_node, pattern):
    if graph.nodes[sub_node]["op_type"] != "Sub":
        return False
    succs = list(graph.successors(sub_node))
    # Either succs=[Mul], [Pow], or [Pow, Div]. In the 3rd pattern, Div is used for (X-EX)/Var.
    # In the first two patterns they use other nodes for that division.
    # We select the Square node as next_node. (Mul/Pow)
    if len(succs) < 1 or len(succs) > 2:
        return False
    pattern["pattern_nodes"].append(sub_node)
    pattern["next_node"] = succs[0]
    return True


def check_Mean(graph, tensors, mean_node, pattern):
    """We will have two dependency to Mean:
    D = Sub(X, Mean)
    Normalized = Mul(D, InvStdDev)
    So the #sucessors should be two, and one of them must be Sub for D
    another is Div (or the same Sub? -> this can be optimized by fuse_identical_sibling_layers.py)
    """
    # We'll have two suceesors, so check len
    succs = list(graph.successors(mean_node))
    # Either succs=[Sub,Mul], [Sub, Sub] or [Sub]
    if len(succs) < 1 or len(succs) > 2:
        return False
    if graph.nodes[succs[0]]["op_type"] != "Sub":
        return False
    if len(succs) == 2:
        succ1_type = graph.nodes[succs[1]]["op_type"]
        if succ1_type == "Sub":
            # the second input can be Div, or [Sub -> Div],
            # just fuse the dummpy Sub here
            pattern["pattern_nodes"].append(succs[1])
        elif succ1_type != "Mul":  # another pattern is Mul
            return False
    else:  # len(succs) == 1, (model: mmlab/vit)
        # we will use this node to indicate the operand of the Division (X-EX)/StdDev
        pattern["pattern_nodes"].append(succs[0])
    pattern["pattern_nodes"].append(mean_node)
    pattern["pattern_inputs"].extend(list(graph.predecessors(mean_node)))
    pattern["next_node"] = succs[0]
    return True
