# -*- coding: utf-8 -*-
"""dod1notebook1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_cD5nydGLeEPrgvyIZa8NrnH-HM-23Wp

****
"""

pip install onnxruntime

dataset_path = '/kaggle/input/imagenet-1k-validation'
onnx_path = 'mobilenetv2_100_fp32.onnx'
fp32_onnx_path = '/kaggle/working/mobilenetv2_100_fp32.onnx'
/kaggle/working/mobilenetv2_100_fp32.onnx

import torch
import timm
import onnx
import onnxruntime
import urllib
from tqdm import tqdm
from PIL import Image
from timm.data import resolve_data_config
from timm.data import create_transform

"""**Accuracy for FP32 Model for 50K images**"""

def calculate_accuracy(data_loader, model, device, model_name):

    correct_top1 = 0
    correct_top5 = 0
    total = 0

    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc='Validation', unit='batch'):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            # Top-1 accuracy
            total += labels.size(0)
            correct_top1 += (predicted == labels).sum().item()

            # Top-5 accuracy
            _, predicted_top5 = outputs.topk(5, 1, largest=True, sorted=True)
            correct_top5 += torch.sum(predicted_top5 == labels.view(-1, 1)).item()

    # Calculate accuracy
    accuracy_top1 = correct_top1 / total
    accuracy_top5 = correct_top5 / total

    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-1): {:.2%}".format(model_name,accuracy_top1))
    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-5): {:.2%}".format(model_name,accuracy_top5))

"""**Accuracy for FP32  Model for 1K images**"""

def calculate_accuracy_1k(data_loader, model, device, model_name):

    correct_top1 = 0
    correct_top5 = 0
    total = 0
    processed_images = 0

    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc='Validation', unit='batch'):

            if processed_images >= 1000:
                 break
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)

            _, predicted = torch.max(outputs, 1)

            total += labels.size(0)
            correct_top1 += (predicted == labels).sum()


            _, predicted_top5 = outputs.topk(5, 1, largest=True, sorted=True)
            correct_top5 += torch.sum(predicted_top5 == labels.view(-1, 1)).item()

            processed_images = processed_images + 1

    accuracy_top1 = correct_top1 / total
    accuracy_top5 = correct_top5 / total

    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-1): {:.2%}".format(model_name,accuracy_top1))
    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-5): {:.2%}".format(model_name,accuracy_top5))

"""**Accuracy for ONNX FP32 Model for 50K images**"""

def evaluate_onnx_model(data_loader, model, onnx_path,model_name):

    correct_onnx_top1 = 0
    correct_onnx_top5 = 0
    total_onnx = 0

    ort_session = onnxruntime.InferenceSession(onnx_path)

    with torch.no_grad(), tqdm(total=len(val_loader.dataset)) as pbar:
        for images, labels in data_loader:
            inputs_onnx = {ort_session.get_inputs()[0].name: images.cpu().numpy()}
            outputs_onnx = ort_session.run(None, inputs_onnx)
            _, predicted_onnx = torch.max(torch.tensor(outputs_onnx[0]), 1)

            # Move labels to the same device as predicted_onnx
            labels = labels.to(predicted_onnx.device)

            # Top-1 accuracy
            total_onnx += labels.size(0)
            correct_onnx_top1 += (predicted_onnx == labels).sum().item()

            # Top-5 accuracy
            _, predicted_top5_onnx = torch.topk(torch.tensor(outputs_onnx[0]), 5, dim=1)
            correct_onnx_top5 += torch.sum(predicted_top5_onnx == labels.view(-1, 1)).item()

            pbar.update(len(images))

    # Calculate accuracy for ONNX model
    accuracy_onnx_top1 = correct_onnx_top1 / total_onnx
    accuracy_onnx_top5 = correct_onnx_top5 / total_onnx

    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-1): {:.2%}".format(model_name, accuracy_onnx_top1))
    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-5): {:.2%}".format(model_name, accuracy_onnx_top5))

"""**Accuracy for ONNX FP32 Model for 1K images**"""

def evaluate_onnx_model_1k(data_loader, model, onnx_path,model_name):
    correct_onnx_top1 = 0
    correct_onnx_top5 = 0
    total_onnx = 0
    processed_images = 0

    ort_session = onnxruntime.InferenceSession(onnx_path)

    with torch.no_grad(), tqdm(total=len(data_loader.dataset)) as pbar:
        for images, labels in data_loader:

            if processed_images >= 1000:
                break

            inputs_onnx = {ort_session.get_inputs()[0].name: images.cpu().numpy()}
            outputs_onnx = ort_session.run(None, inputs_onnx)
            _, predicted_onnx = torch.max(torch.tensor(outputs_onnx[0]), 1)

            # Move labels to the same device as predicted_onnx
            labels = labels.to(predicted_onnx.device)

            # Top-1 accuracy
            total_onnx += labels.size(0)
            correct_onnx_top1 += (predicted_onnx == labels).sum().item()

            # Top-5 accuracy
            _, predicted_top5_onnx = torch.topk(torch.tensor(outputs_onnx[0]), 5, dim=1)
            correct_onnx_top5 += torch.sum(predicted_top5_onnx == labels.view(-1, 1)).item()

            pbar.update(len(images))

            processed_images = processed_images + 1

    # Calculate accuracy for ONNX model
    accuracy_onnx_top1 = correct_onnx_top1 / total_onnx
    accuracy_onnx_top5 = correct_onnx_top5 / total_onnx

    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-1): {:.2%}".format(model_name, accuracy_onnx_top1))
    print("Accuracy of {} FP32 PyTorch model on the ImageNet validation set (Top-5): {:.2%}".format(model_name, accuracy_onnx_top5))

def onnx_export(onnx_path):
    dummy_input = torch.randn(1, 3, 224, 224)
    torch.onnx.export(model.to("cpu"), dummy_input, onnx_path)

def load_model(model_name, pretrained=True, device='cuda'):
    model = timm.create_model(model_name, pretrained=pretrained)
    model.eval()
    model.to(device)
    return model

def load_dataset(dataset_path,model):
    data_config = timm.data.resolve_model_data_config(model)
    transforms = timm.data.create_transform(**data_config, is_training=False)
    dataset = timm.data.ImageDataset(dataset_path, transform=transforms)
    data_loader = timm.data.create_loader(dataset, (1,3,224,224), 1)
    return data_loader

def main(args):

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

     # Load MobileNetV2 model.
    model = load_model(args)

     # Load dataset using the loaded model.
    data_loader = load_dataset(dataset_path, model)

     # Calculate accuracy of the model on the dataset.
    calculate_accuracy(data_loader, model, device, args)

     # Calculate accuracy of the model on ImageNet-1K dataset.
    calculate_accuracy_1k(data_loader, model, device, args)

    # Export the model to ONNX format.
    onnx_export(onnx_path)

    # evaluate_onnx_model(data_loader, model, onnx_path, calculate_accuracy(data_loader, model, device, 'mobilenetv2_140')  # Evaluate ONNX model accuracy.

    # Evaluate ONNX model accuracy on ImageNet-1K dataset.
    evaluate_onnx_model_1k(data_loader, model, fp32_onnx_path, args)  # Evaluate ONNX model accuracy on ImageNet-1K dataset.

if __name__ == "__main__":
    args = 'mobilenetv2_100'
    main(args)
    args = 'mobilenetv2_140'
    main(args)